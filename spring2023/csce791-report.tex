\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
%\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
%\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent

\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=22mm,
 bottom=22mm
 }

\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{enumerate}
\usepackage{arcs}
\usepackage{cancel}
\usepackage{xfrac}
\usepackage{amsthm}
\usepackage{gensymb}
\usepackage{xspace}
\usepackage{array}
\usepackage{tabularx}
\usepackage{url}
\usepackage{hyperref}
%\usepackage{ctex}

%SetFonts

%SetFonts

\usepackage[inline]{asymptote}


\pagestyle{fancy}
\fancyhf{}
\rhead{Zifei (David) Zhong, \url{zhongz@email.sc.edu}}
\lhead{\leftmark}
\lfoot{\href{https://github.com/zfzhong/csce791}{github.com/zfzhong/csce791/spring2023}}
\rfoot{\thepage}

\title{CSCE 791 Course Report}
\author{Zifei (David) Zhong}
%\date{}							% Activate to display a given date or no date

\newcommand{\latex}{\LaTeX\xspace}


\begin{document}
\maketitle

This file includes all my course reports for CSCE 791 for the semester
of Spring 2023. I will write a summary for each talk presented in the
seminar. I will also include interesting questions raised by the
audience, as well as corresponding responses from the speaker.\\

\begin{center}
\begin{tabularx}{0.65\textwidth}{r X}
\textbf{Course:} & CSCE 791: Seminar in Advances in Computing\\
\textbf{Location:} & Swearingen Engineering Center 2A17\\
\textbf{Time:} & Friday 2:20pm - 3:10pm\\
\textbf{Semester:} & Spring 2023
\end{tabularx}
\end{center}

\newpage
\section{Talk on January 18, 2023}
\begin{tabularx} {\textwidth}{r X}
\textbf{Topic}: & From Self-Adaptation to Self-Evolution \\
\textbf{Speaker:} & Danny Weyns \\
\end{tabularx}

\subsection{Review}
In this talk, Dr. Weyns introduced the self-adaptation concept of computer systems and the conceptual model of the self-adaptive system in general. These were very abstract concepts that require the audience to have a proper understanding of software engineering or architecture. He then brought up the question of why ``just self-adaptation'' is not enough. He introduced the Operational Design Domain (ODD) of a system and claimed that the evolution of a system means enhancing the ODD of a system. He gave an example IoT system to explain how to enhance the ODD of a system. To enhance the ODD, updating current software is required, and all that requirements point to a new software architecture. Finally, he introduced the architecture of a system with evolution as the ultimate solution. The new architecture has two new components: computing warehouse and data storage, which are two major components that support evolutional computing. He also talked about the challenges to realize such system architecture.

The talk was well structured and it flowed naturally, even though some concepts were quite abstract at the beginning. The ODD concept is a great abstraction, and the new architecture to support software evolution seems reasonable. The new architecture proposal can be viewed as a design to install a brain for a computer system. I expect to know, in the near future, what rules engineers should follow to install such brains for future computer systems.

\subsection{Questions}
I didn't ask a question because I had conflict class schedule (CSCE 574), for which I was not able to attend the talk in-person.

\newpage
\section{Talk on January 27, 2023}
\begin{tabularx} {\textwidth}{r X}
\textbf{Topic}: & Energy-Efficient Deployment of Machine Learning Workloads on Neuromorphic Hardware \\
\textbf{Speaker:} & R. Zand\\
\end{tabularx}

\subsection{Review}
In this talk, Dr. Zand first introduced the history of Neuromorphic Computing, and then he presented the challenges that exist in the area. He later asked his student to present their work of deploying machine learning tasks on their neuromorphic hardware -- edge devices. The presented work had been published in two research papers. Their work is to convert a deep neural network to a spike neural network and use the spike neural network to perform regular machine learning tasks such as static sign language image recognition. They also provided optimization for the spike neural network to achieve better performance. They used image classification tasks for evaluation, they tested their approach on different neuromorphic computing devices. 

Dr. Zand and his group carried out a series of experiments to show that Neuromorphic Computing can finish machine learning tasks with lower energy consumption. I believe it would be better if he presents the detailed challenges that exist in converting deep neural networks to spiking neural networks, and how his group tackles these challenges. In addition, we would like to know the specific scenarios in which the spiking neural network can be employed to solve real-world problems. Can all machine learning applications be deployed in neuromorphic computing devices, or only certain categories of applications are suitable? It would make their work much more impressive if these questions get addressed properly in their work.


\subsection{Questions}
I asked two questions, both about the edge devices. Since he didn't mention much about the limitation of neuromorphic computing, I also asked whether or not we should push every machine learning application to neuromorphic computing platforms.

\newpage
\section{Talk on February 3, 2023}
\begin{tabularx} {\textwidth}{r X}
\textbf{Topic}: &  In Silico Reconstruction of the Brain \\
\textbf{Speaker:} & Christian O'Reilly\\
\end{tabularx}

\subsection{Review}
Dr. O'Reilly introduced the complexity of a human brain from two dimensions: the physical size dimension ranging from a neuron to a brain, and the time scale dimension ranging from nanoseconds to seconds. He then compared the human brain with the complexity of the computer CPU and transistors and seemly indicated that there is a long way to go before researchers can barely approach the complexity of a human brain with inventions based on modern technology. If we compare the power consumption of modern technology with that of a human brain, we almost see no hope in inventing a human brain based on computer technology. 

Nevertheless, Dr. O'Reilly then introduced some existing research projects that focus on simulating a brain or a neuron. Specifically, he introduced the Blue Brain Project to reconstruct the brain using models of neurons. He also mentioned that much data get shared in an open science framework to enable modeling work in human brain simulation research. He also discussed some important issues such as the balance between computation power and resource waste in simulating a human brain.

Overall, Dr. O'Reilly did a great work presenting the complexity of the human brain and did a vivid comparison to the complexity of a computer CPU. The presentation is very informative. He used some good examples in his presentation and brought much humor to the audience. For example, a TED talk in 2009 claimed to create the human brain in 10 years. His introduction to the Blue Brain Project and his takeaway messages are also informative. I pretty much enjoyed this talk. 

I was expecting to hear some of his research progress (or his ideas) in this field (simulating the human brain). He seemed not plan to include that in this talk. I believe we just leave that for his next talk.

\subsection{Questions}
I asked him, to the best of his knowledge, are there any research projects in simulating a human brain have made significant progress on the path? He didn't notice my question though.

\end{document} 
